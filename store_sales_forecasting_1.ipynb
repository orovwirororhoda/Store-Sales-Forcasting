{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè™ Store Sales Time Series Forecasting\n",
        "### ECON 5140: Applied Econometrics ‚Äî Midterm Project | Spring 2025\n",
        "\n",
        "> **Dataset:** [Kaggle Store Sales Competition](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data)  \n",
        "> **Models:** SARIMA ¬∑ ETS (Holt-Winters) ¬∑ Prophet  \n",
        "> **Forecasting scope:** Aggregate sales + Product family level (GROCERY I, BEVERAGES)  \n",
        "> **Horizon:** 30 days ahead\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Setup\n",
        "\n",
        "Run the cell below to install dependencies if needed. Prophet requires a separate install."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install dependencies (run once)\n",
        "# !pip install pandas numpy matplotlib seaborn statsmodels scikit-learn\n",
        "# !pip install prophet\n",
        "# !pip install kaggle  # for downloading the dataset\n",
        "\n",
        "# Download Kaggle data (after setting up kaggle.json credentials):\n",
        "# !kaggle competitions download -c store-sales-time-series-forecasting -p ./data\n",
        "# !cd data && unzip store-sales-time-series-forecasting.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ 0. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "ECON 5140: Applied Econometrics ‚Äî Midterm Project\n",
        "Project Option 3: Store Sales Time Series Forecasting\n",
        "\n",
        "Authors: [Your Group Names]\n",
        "Date: Spring 2025\n",
        "\n",
        "This script covers:\n",
        "  1. Data Loading & Preprocessing\n",
        "  2. Exploratory Data Analysis (EDA)\n",
        "  3. Feature Engineering\n",
        "  4. Forecasting Models: ARIMA, ETS, Prophet\n",
        "  5. Evaluation: MAE, RMSE, MAPE\n",
        "  6. Visualizations & Confidence Intervals\n",
        "  7. Both aggregate and product-family-level forecasts\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üì¶ 0. SETUP & IMPORTS\n",
        "\n",
        "Import all required libraries and configure plot styling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "# Statsmodels (ARIMA, ETS)\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Prophet\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    PROPHET_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Prophet not installed. Install: pip install prophet --break-system-packages\")\n",
        "    PROPHET_AVAILABLE = False\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Plot style\n",
        "plt.rcParams.update({\n",
        "    \"figure.facecolor\": \"white\",\n",
        "    \"axes.facecolor\": \"white\",\n",
        "    \"axes.grid\": True,\n",
        "    \"grid.alpha\": 0.3,\n",
        "    \"font.size\": 11,\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False\n",
        "})\n",
        "PALETTE = [\"#1C7293\", \"#F96167\", \"#28A745\", \"#F4A261\", \"#6D2E46\"]\n",
        "\n",
        "# Output folder for plots\n",
        "PLOTS_DIR = Path(\"plots\")\n",
        "PLOTS_DIR.mkdir(exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìÇ 1. DATA LOADING\n",
        "\n",
        "Two loaders are provided:\n",
        "- **`load_data()`** ‚Äî reads real Kaggle CSV files from `./data/`\n",
        "- **`generate_synthetic_data()`** ‚Äî creates realistic demo data when Kaggle files aren't available yet\n",
        "\n",
        "The `main()` function automatically picks the right one.\n",
        "\n",
        "**For submission:** Use real Kaggle data: place `train.csv` (and other competition files) in `./data/` so results reflect actual store sales; otherwise the pipeline uses synthetic data for demonstration."
      ],
      "id": "48b9c5cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    \"\"\"\n",
        "    Load Kaggle Store Sales competition data.\n",
        "\n",
        "    Data files (download from Kaggle):\n",
        "      train.csv        - daily sales by store/family\n",
        "      test.csv         - prediction horizon\n",
        "      stores.csv       - store metadata\n",
        "      oil.csv          - daily oil price (macroeconomic indicator)\n",
        "      holidays_events.csv - Ecuador public holidays\n",
        "\n",
        "    Download instructions:\n",
        "      kaggle competitions download -c store-sales-time-series-forecasting -p ./data\n",
        "      cd ./data && unzip store-sales-time-series-forecasting.zip\n",
        "    \"\"\"\n",
        "    data_dir = Path(data_dir)\n",
        "\n",
        "    print(\"Loading data files...\")\n",
        "    train   = pd.read_csv(data_dir / \"train.csv\",            parse_dates=[\"date\"])\n",
        "    test    = pd.read_csv(data_dir / \"test.csv\",             parse_dates=[\"date\"])\n",
        "    stores  = pd.read_csv(data_dir / \"stores.csv\")\n",
        "    oil     = pd.read_csv(data_dir / \"oil.csv\",              parse_dates=[\"date\"])\n",
        "    hol     = pd.read_csv(data_dir / \"holidays_events.csv\",  parse_dates=[\"date\"])\n",
        "\n",
        "    print(f\"  Train: {train.shape}  |  Test: {test.shape}\")\n",
        "    print(f\"  Date range: {train['date'].min().date()} ‚Üí {train['date'].max().date()}\")\n",
        "    print(f\"  Stores: {train['store_nbr'].nunique()}  |  Families: {train['family'].nunique()}\")\n",
        "    return train, test, stores, oil, hol\n",
        "\n",
        "\n",
        "def generate_synthetic_data():\n",
        "    \"\"\"\n",
        "    Generate realistic synthetic data for demonstration when Kaggle data\n",
        "    is not yet downloaded. Mirrors the structure of the actual dataset.\n",
        "    \"\"\"\n",
        "    print(\"Generating synthetic demonstration data...\")\n",
        "    np.random.seed(42)\n",
        "\n",
        "    dates  = pd.date_range(\"2013-01-01\", \"2017-08-15\", freq=\"D\")\n",
        "    stores = list(range(1, 55))\n",
        "    families = [\n",
        "        \"GROCERY I\", \"BEVERAGES\", \"PRODUCE\", \"CLEANING\",\n",
        "        \"DAIRY\", \"BREAD/BAKERY\", \"POULTRY\", \"MEATS\",\n",
        "        \"PERSONAL CARE\", \"DELI\"\n",
        "    ]\n",
        "\n",
        "    rows = []\n",
        "    for store in stores:\n",
        "        for family in families:\n",
        "            base     = np.random.uniform(200, 2000)\n",
        "            trend    = np.linspace(0, base * 0.2, len(dates))\n",
        "            seasonal = base * 0.3 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\n",
        "            weekly   = base * 0.15 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)\n",
        "            noise    = np.random.normal(0, base * 0.05, len(dates))\n",
        "            sales    = np.maximum(0, base + trend + seasonal + weekly + noise)\n",
        "            for i, d in enumerate(dates):\n",
        "                rows.append({\"date\": d, \"store_nbr\": store,\n",
        "                             \"family\": family, \"sales\": sales[i],\n",
        "                             \"onpromotion\": int(np.random.random() < 0.1)})\n",
        "\n",
        "    train = pd.DataFrame(rows)\n",
        "\n",
        "    # Test: last 16 days\n",
        "    test_dates = pd.date_range(\"2017-08-16\", periods=16)\n",
        "    test_rows  = []\n",
        "    for store in stores:\n",
        "        for family in families:\n",
        "            for d in test_dates:\n",
        "                test_rows.append({\"date\": d, \"store_nbr\": store, \"family\": family, \"onpromotion\": 0})\n",
        "    test = pd.DataFrame(test_rows)\n",
        "\n",
        "    stores_df = pd.DataFrame({\n",
        "        \"store_nbr\": stores,\n",
        "        \"city\": np.random.choice([\"Quito\",\"Guayaquil\",\"Cuenca\",\"Ambato\"], 54),\n",
        "        \"state\": np.random.choice([\"Pichincha\",\"Guayas\",\"Azuay\"], 54),\n",
        "        \"type\": np.random.choice([\"A\",\"B\",\"C\",\"D\",\"E\"], 54),\n",
        "        \"cluster\": np.random.randint(1, 18, 54)\n",
        "    })\n",
        "\n",
        "    oil = pd.DataFrame({\n",
        "        \"date\": pd.date_range(\"2013-01-01\", \"2017-08-31\"),\n",
        "        \"dcoilwtico\": 90 + np.cumsum(np.random.normal(0, 1.5, len(pd.date_range(\"2013-01-01\",\"2017-08-31\"))))\n",
        "    })\n",
        "\n",
        "    hol = pd.DataFrame({\n",
        "        \"date\": pd.to_datetime([\"2013-01-01\",\"2013-04-01\",\"2013-12-25\",\n",
        "                                \"2014-01-01\",\"2014-04-18\",\"2014-12-25\",\n",
        "                                \"2015-01-01\",\"2015-04-03\",\"2015-12-25\",\n",
        "                                \"2016-01-01\",\"2016-03-25\",\"2016-12-25\",\n",
        "                                \"2017-01-01\",\"2017-04-14\",\"2017-12-25\"]),\n",
        "        \"type\": \"Holiday\",\n",
        "        \"locale\": \"National\",\n",
        "        \"locale_name\": \"Ecuador\",\n",
        "        \"description\": [\"New Year\",\"Easter\",\"Christmas\"] * 5,\n",
        "        \"transferred\": False\n",
        "    })\n",
        "\n",
        "    print(f\"  Synthetic Train: {train.shape}\")\n",
        "    print(f\"  Date range: {train['date'].min().date()} ‚Üí {train['date'].max().date()}\")\n",
        "    return train, test, stores_df, oil, hol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üîß 2. PREPROCESSING\n",
        "\n",
        "Merge auxiliary datasets (stores, oil prices, holidays) onto the training data.  \n",
        "Create time features and clean zero/negative sales values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def preprocess(train, stores, oil, hol):\n",
        "    \"\"\"Merge auxiliary data, handle missing values, create features.\"\"\"\n",
        "\n",
        "    # Merge store metadata\n",
        "    df = train.merge(stores, on=\"store_nbr\", how=\"left\")\n",
        "\n",
        "    # Merge oil prices (forward-fill missing weekends)\n",
        "    oil_full = oil.set_index(\"date\").reindex(\n",
        "        pd.date_range(oil[\"date\"].min(), oil[\"date\"].max(), freq=\"D\")\n",
        "    ).ffill().reset_index().rename(columns={\"index\": \"date\"})\n",
        "    df = df.merge(oil_full, on=\"date\", how=\"left\")\n",
        "\n",
        "    # Merge holidays\n",
        "    hol_national = hol[hol[\"locale\"] == \"National\"][[\"date\",\"type\",\"description\"]].copy()\n",
        "    hol_national.columns = [\"date\",\"holiday_type\",\"holiday_desc\"]\n",
        "    df = df.merge(hol_national, on=\"date\", how=\"left\")\n",
        "    df[\"is_holiday\"] = df[\"holiday_type\"].notna().astype(int)\n",
        "\n",
        "    # Time features\n",
        "    df[\"year\"]       = df[\"date\"].dt.year\n",
        "    df[\"month\"]      = df[\"date\"].dt.month\n",
        "    df[\"day\"]        = df[\"date\"].dt.day\n",
        "    df[\"dayofweek\"]  = df[\"date\"].dt.dayofweek\n",
        "    df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
        "    df[\"quarter\"]    = df[\"date\"].dt.quarter\n",
        "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(int)\n",
        "\n",
        "    # Handle zeros (genuine closed days vs missing)\n",
        "    df[\"sales\"] = df[\"sales\"].clip(lower=0)\n",
        "\n",
        "    print(f\"Preprocessed DataFrame shape: {df.shape}\")\n",
        "    print(f\"  Missing oil prices: {df['dcoilwtico'].isna().sum()}\")\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä 3. AGGREGATE TIME SERIES\n",
        "\n",
        "Build two series structures:\n",
        "- **Aggregate**: sum of all stores √ó all families ‚Üí single daily total\n",
        "- **Family-level**: separate series per product family (top N)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def build_aggregate_series(df):\n",
        "    \"\"\"Aggregate all stores √ó families ‚Üí single daily total sales series.\"\"\"\n",
        "    agg = df.groupby(\"date\")[\"sales\"].sum().reset_index()\n",
        "    agg = agg.sort_values(\"date\").set_index(\"date\")\n",
        "    agg.index.freq = \"D\"\n",
        "    print(f\"Aggregate series: {len(agg)} daily observations\")\n",
        "    return agg\n",
        "\n",
        "\n",
        "def build_family_series(df, top_n=5):\n",
        "    \"\"\"Aggregate by product family; return dict of top N families.\"\"\"\n",
        "    family_totals = df.groupby(\"family\")[\"sales\"].sum().sort_values(ascending=False)\n",
        "    top_families  = family_totals.head(top_n).index.tolist()\n",
        "    print(f\"Top {top_n} families: {top_families}\")\n",
        "\n",
        "    series_dict = {}\n",
        "    for fam in top_families:\n",
        "        s = df[df[\"family\"] == fam].groupby(\"date\")[\"sales\"].sum().sort_values()\n",
        "        s.index = pd.DatetimeIndex(s.index)\n",
        "        s.index.freq = \"D\"\n",
        "        series_dict[fam] = s\n",
        "    return series_dict, top_families"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üîç 4. EXPLORATORY DATA ANALYSIS\n",
        "\n",
        "Six EDA visualizations:\n",
        "1. **Total daily sales over time** ‚Äî level, trend, and volatility\n",
        "2. **Sales by product family** (stacked subplots) ‚Äî relative importance and dynamics by family\n",
        "3. **Seasonal decomposition** (trend, seasonal, residual) ‚Äî informs choice of seasonal period\n",
        "4. **Day-of-week distribution** (box plots) ‚Äî weekly seasonality (e.g. weekend vs weekday)\n",
        "5. **Monthly average sales** (bar chart) ‚Äî within-year pattern\n",
        "6. **ACF / PACF** ‚Äî autocorrelation structure for ARIMA order selection\n",
        "\n",
        "Also performs an **ADF stationarity test**; non-stationarity suggests differencing (e.g. `d=1` in SARIMA)."
      ],
      "id": "49e353d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def eda_aggregate(agg, family_dict, top_families):\n",
        "    \"\"\"Comprehensive EDA plots.\"\"\"\n",
        "\n",
        "    # --- 4.1 Total Sales Over Time ---\n",
        "    fig, ax = plt.subplots(figsize=(14, 4))\n",
        "    ax.plot(agg.index, agg[\"sales\"] / 1e6, color=PALETTE[0], lw=1.2)\n",
        "    ax.set(title=\"Total Daily Store Sales (All Families, All Stores)\",\n",
        "           xlabel=\"Date\", ylabel=\"Sales (Millions)\")\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(PLOTS_DIR / \"01_aggregate_sales.png\", dpi=150)\n",
        "    plt.show()\n",
        "    print(\"Plot saved: 01_aggregate_sales.png\")\n",
        "\n",
        "    # --- 4.2 Sales by Product Family ---\n",
        "    fig, axes = plt.subplots(len(top_families), 1, figsize=(14, 3*len(top_families)), sharex=True)\n",
        "    for ax, fam, color in zip(axes, top_families, PALETTE):\n",
        "        s = family_dict[fam]\n",
        "        ax.fill_between(s.index, s.values, alpha=0.3, color=color)\n",
        "        ax.plot(s.index, s.values, color=color, lw=1)\n",
        "        ax.set_ylabel(fam, fontsize=9)\n",
        "    axes[-1].set_xlabel(\"Date\")\n",
        "    fig.suptitle(\"Daily Sales by Top Product Family\", fontsize=13, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(PLOTS_DIR / \"02_family_sales.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 4.3 Seasonal Decomposition ---\n",
        "    decomp = seasonal_decompose(agg[\"sales\"].dropna(), model=\"additive\", period=365)\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
        "    titles = [\"Observed\", \"Trend\", \"Seasonal\", \"Residual\"]\n",
        "    components = [decomp.observed, decomp.trend, decomp.seasonal, decomp.resid]\n",
        "    for ax, comp, title in zip(axes, components, titles):\n",
        "        ax.plot(comp.index, comp.values, color=PALETTE[0], lw=1)\n",
        "        ax.set_title(title, fontsize=10)\n",
        "    fig.suptitle(\"Seasonal Decomposition ‚Äî Aggregate Sales (Period=365)\", fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(PLOTS_DIR / \"03_decomposition.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 4.4 Weekly seasonality box plot ---\n",
        "    tmp = agg.copy().reset_index()\n",
        "    tmp[\"day_name\"] = pd.to_datetime(tmp[\"date\"]).dt.day_name()\n",
        "    day_order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    tmp[\"day_name\"] = pd.Categorical(tmp[\"day_name\"], categories=day_order, ordered=True)\n",
        "    tmp.boxplot(column=\"sales\", by=\"day_name\", ax=ax, patch_artist=True)\n",
        "    ax.set(title=\"Sales Distribution by Day of Week\",\n",
        "           xlabel=\"Day\", ylabel=\"Daily Sales\")\n",
        "    plt.suptitle(\"\")\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(PLOTS_DIR / \"04_weekly_pattern.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 4.5 Monthly pattern ---\n",
        "    tmp[\"month\"] = pd.to_datetime(tmp[\"date\"]).dt.month\n",
        "    monthly = tmp.groupby(\"month\")[\"sales\"].mean()\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    ax.bar(monthly.index, monthly.values, color=PALETTE[0], alpha=0.8)\n",
        "    ax.set(title=\"Average Daily Sales by Month\",\n",
        "           xlabel=\"Month\", ylabel=\"Avg Daily Sales\",\n",
        "           xticks=range(1,13),\n",
        "           xticklabels=[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"])\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(PLOTS_DIR / \"05_monthly_pattern.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 4.6 ACF / PACF ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "    plot_acf(agg[\"sales\"].dropna(),  lags=60, ax=axes[0], title=\"ACF ‚Äî Aggregate Sales\")\n",
        "    plot_pacf(agg[\"sales\"].dropna(), lags=60, ax=axes[1], title=\"PACF ‚Äî Aggregate Sales\", method=\"ywm\")\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(PLOTS_DIR / \"06_acf_pacf.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 4.7 Stationarity tests ---\n",
        "    series = agg[\"sales\"].dropna()\n",
        "    adf_stat, adf_p, *_ = adfuller(series)\n",
        "    print(\"\\n=== Stationarity Tests ===\")\n",
        "    print(f\"  ADF  statistic: {adf_stat:.4f}  p-value: {adf_p:.4f}\")\n",
        "    if adf_p < 0.05:\n",
        "        print(\"  ‚Üí Series is stationary (ADF rejects unit root)\")\n",
        "    else:\n",
        "        print(\"  ‚Üí Series may be non-stationary; differencing recommended\")\n",
        "\n",
        "    print(\"\\nEDA complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**EDA interpretation:** The total sales plot shows a clear upward trend and some volatility. Seasonal decomposition (period=365) separates a smooth trend from an annual cycle and residuals, which justifies including yearly seasonality in ETS and Prophet. The day-of-week box plot typically shows higher sales on weekends; the monthly bar chart reveals within-year peaks (e.g. year-end). Together these support using both weekly and yearly seasonality in the models. The ACF/PACF plots guide ARIMA order choice (e.g. slow ACF decay suggests differencing). If the ADF test indicates non-stationarity (p > 0.05), we use `d=1` in SARIMA."
      ],
      "id": "d4b456c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÇÔ∏è 5. TRAIN / VALIDATION SPLIT\n",
        "\n",
        "Chronological split: hold out the **last 30 days** as validation.  \n",
        "No random shuffling ‚Äî time series must be split in order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_val_split(series, val_days=30):\n",
        "    \"\"\"Hold out last `val_days` observations as validation set.\"\"\"\n",
        "    cutoff = series.index[-1] - pd.Timedelta(days=val_days)\n",
        "    train  = series[series.index <= cutoff]\n",
        "    val    = series[series.index >  cutoff]\n",
        "    print(f\"Training:   {train.index.min().date()} ‚Üí {train.index.max().date()} ({len(train)} obs)\")\n",
        "    print(f\"Validation: {val.index.min().date()}   ‚Üí {val.index.max().date()} ({len(val)} obs)\")\n",
        "    return train, val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìè 6. EVALUATION METRICS\n",
        "\n",
        "Three standard forecasting metrics:\n",
        "| Metric | Formula | Notes |\n",
        "|--------|---------|-------|\n",
        "| **MAE** | mean\\|actual ‚àí forecast\\| | Original units, interpretable |\n",
        "| **RMSE** | ‚àömean(actual ‚àí forecast)¬≤ | Penalizes large errors |\n",
        "| **MAPE** | mean\\|actual ‚àí forecast\\| / actual √ó 100 | Scale-free % error |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mape(actual, forecast):\n",
        "    \"\"\"Mean Absolute Percentage Error (avoids division by zero).\"\"\"\n",
        "    actual, forecast = np.array(actual), np.array(forecast)\n",
        "    mask = actual != 0\n",
        "    return np.mean(np.abs((actual[mask] - forecast[mask]) / actual[mask])) * 100\n",
        "\n",
        "\n",
        "def evaluate(actual, forecast, model_name=\"Model\"):\n",
        "    \"\"\"Compute and display MAE, RMSE, MAPE.\"\"\"\n",
        "    mae_v  = mean_absolute_error(actual, forecast)\n",
        "    rmse_v = np.sqrt(mean_squared_error(actual, forecast))\n",
        "    mape_v = mape(actual, forecast)\n",
        "    print(f\"  [{model_name}]  MAE={mae_v:,.0f}  RMSE={rmse_v:,.0f}  MAPE={mape_v:.2f}%\")\n",
        "    return {\"model\": model_name, \"MAE\": mae_v, \"RMSE\": rmse_v, \"MAPE\": mape_v}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìà 7. ARIMA MODEL\n",
        "\n",
        "**SARIMA(1,1,1)√ó(1,1,0)[4]** fitted on weekly-aggregated data.\n",
        "\n",
        "- `d=1`: first differencing for stationarity\n",
        "- `seasonal_order=(1,1,0,4)`: quarterly seasonality at weekly frequency (4 weeks ‚âà 1 month)\n",
        "- 95% confidence intervals from `get_forecast().conf_int()`"
      ],
      "id": "159b2a44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_arima(train_series, val_series, order=(2, 1, 2),\n",
        "              seasonal_order=(1, 1, 1, 7), label=\"Aggregate\"):\n",
        "    \"\"\"\n",
        "    Fit SARIMA model. Uses (1,1,1)(1,1,0)[4]: quarterly seasonality at weekly frequency.\n",
        "    \"\"\"\n",
        "    print(f\"\\nFitting ARIMA {order}x{seasonal_order} for {label}...\")\n",
        "\n",
        "    # Weekly aggregation speeds up ARIMA fitting considerably\n",
        "    train_w = train_series.resample(\"W\").sum()\n",
        "    val_w   = val_series.resample(\"W\").sum()\n",
        "\n",
        "    model = SARIMAX(\n",
        "        train_w,\n",
        "        order=(1, 1, 1),\n",
        "        seasonal_order=(1, 1, 0, 4),   # quarterly seasonality at weekly freq\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False\n",
        "    )\n",
        "    results = model.fit(disp=False)\n",
        "\n",
        "    # Forecast\n",
        "    n_periods   = len(val_w)\n",
        "    forecast_w  = results.get_forecast(steps=n_periods + 4)  # +4 weeks extra\n",
        "    pred_mean   = forecast_w.predicted_mean\n",
        "    pred_ci     = forecast_w.conf_int()\n",
        "\n",
        "    metrics = evaluate(val_w.values, pred_mean.values[:len(val_w)], f\"ARIMA ({label})\")\n",
        "    print(f\"  AIC: {results.aic:.1f}  |  BIC: {results.bic:.1f}\")\n",
        "\n",
        "    return results, pred_mean, pred_ci, metrics, train_w, val_w\n",
        "\n",
        "\n",
        "def plot_arima(train_w, val_w, pred_mean, pred_ci, label=\"Aggregate\"):\n",
        "    fig, ax = plt.subplots(figsize=(14, 5))\n",
        "    ax.plot(train_w.index[-52:], train_w.values[-52:], color=PALETTE[0], lw=1.5, label=\"Train (last year)\")\n",
        "    ax.plot(val_w.index,  val_w.values,  color=PALETTE[1], lw=2, label=\"Actual (Validation)\")\n",
        "    ax.plot(pred_mean.index[:len(val_w)+4], pred_mean.values[:len(val_w)+4],\n",
        "            color=PALETTE[2], lw=2, linestyle=\"--\", label=\"ARIMA Forecast\")\n",
        "    ax.fill_between(\n",
        "        pred_ci.index[:len(val_w)+4],\n",
        "        pred_ci.iloc[:len(val_w)+4, 0],\n",
        "        pred_ci.iloc[:len(val_w)+4, 1],\n",
        "        alpha=0.2, color=PALETTE[2], label=\"95% CI\"\n",
        "    )\n",
        "    ax.axvline(val_w.index[0], color=\"gray\", linestyle=\":\", lw=1.5)\n",
        "    ax.set(title=f\"ARIMA Forecast ‚Äî {label} (Weekly)\", xlabel=\"Date\", ylabel=\"Weekly Sales\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    fname = PLOTS_DIR / f\"07_arima_{label.replace(' ','_')}.png\"\n",
        "    fig.savefig(fname, dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"Plot saved: {fname.name}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c5c04b8c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìâ 8. ETS MODEL (Holt-Winters)\n",
        "\n",
        "**Holt-Winters Exponential Smoothing** (additive trend + additive seasonality).\n",
        "\n",
        "- `damped_trend=True`: prevents over-extrapolation\n",
        "- `seasonal_periods=52`: annual cycle at weekly frequency\n",
        "- Parameters optimized automatically via MLE\n",
        "- Approximate 95% CI: ¬±1.96 √ó residual std dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_ets(train_series, val_series, label=\"Aggregate\"):\n",
        "    \"\"\"\n",
        "    Fit Holt-Winters Exponential Smoothing.\n",
        "    Trend: additive  |  Seasonality: additive, period=7 (weekly)\n",
        "    \"\"\"\n",
        "    print(f\"\\nFitting ETS (Holt-Winters) for {label}...\")\n",
        "\n",
        "    train_w = train_series.resample(\"W\").sum()\n",
        "    val_w   = val_series.resample(\"W\").sum()\n",
        "\n",
        "    model = ExponentialSmoothing(\n",
        "        train_w,\n",
        "        trend=\"add\",\n",
        "        seasonal=\"add\",\n",
        "        seasonal_periods=52,   # annual seasonality at weekly freq\n",
        "        damped_trend=True\n",
        "    )\n",
        "    results = model.fit(optimized=True)\n",
        "\n",
        "    n_periods  = len(val_w) + 4\n",
        "    forecast_w = results.forecast(n_periods)\n",
        "\n",
        "    # Bootstrap CI (ETS doesn't provide native CI)\n",
        "    residuals = results.resid.std()\n",
        "    z_95 = 1.96\n",
        "    ci_lower = forecast_w - z_95 * residuals\n",
        "    ci_upper = forecast_w + z_95 * residuals\n",
        "\n",
        "    metrics = evaluate(val_w.values, forecast_w.values[:len(val_w)], f\"ETS ({label})\")\n",
        "\n",
        "    return results, forecast_w, ci_lower, ci_upper, metrics, train_w, val_w\n",
        "\n",
        "\n",
        "def plot_ets(train_w, val_w, forecast_w, ci_lower, ci_upper, label=\"Aggregate\"):\n",
        "    fig, ax = plt.subplots(figsize=(14, 5))\n",
        "    ax.plot(train_w.index[-52:], train_w.values[-52:], color=PALETTE[0], lw=1.5, label=\"Train\")\n",
        "    ax.plot(val_w.index, val_w.values,  color=PALETTE[1], lw=2, label=\"Actual\")\n",
        "    ax.plot(forecast_w.index, forecast_w.values, color=PALETTE[3], lw=2, linestyle=\"--\", label=\"ETS Forecast\")\n",
        "    ax.fill_between(forecast_w.index, ci_lower, ci_upper, alpha=0.2, color=PALETTE[3], label=\"95% CI (approx)\")\n",
        "    ax.axvline(val_w.index[0], color=\"gray\", linestyle=\":\", lw=1.5)\n",
        "    ax.set(title=f\"ETS Holt-Winters Forecast ‚Äî {label} (Weekly)\", xlabel=\"Date\", ylabel=\"Weekly Sales\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    fname = PLOTS_DIR / f\"08_ets_{label.replace(' ','_')}.png\"\n",
        "    fig.savefig(fname, dpi=150)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üîÆ 9. PROPHET MODEL\n",
        "\n",
        "**Meta Prophet** ‚Äî decomposable Bayesian time series model.\n",
        "\n",
        "- `seasonality_mode='multiplicative'`: amplitude scales with trend\n",
        "- Built-in yearly + weekly seasonality (Fourier series)\n",
        "- Ecuador national holidays via `add_country_holidays('EC')`\n",
        "- `changepoint_prior_scale=0.05`: moderate flexibility for trend shifts\n",
        "- Native 80% uncertainty intervals from posterior sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_prophet(train_series, val_series, label=\"Aggregate\"):\n",
        "    \"\"\"\n",
        "    Fit Meta Prophet with built-in yearly + weekly seasonality.\n",
        "    Also includes holiday effects.\n",
        "    \"\"\"\n",
        "    if not PROPHET_AVAILABLE:\n",
        "        print(\"Prophet not available ‚Äî skipping.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    print(f\"\\nFitting Prophet for {label}...\")\n",
        "\n",
        "    def to_prophet_df(s):\n",
        "        return pd.DataFrame({\"ds\": s.index, \"y\": s.values})\n",
        "\n",
        "    train_df = to_prophet_df(train_series)\n",
        "    val_df   = to_prophet_df(val_series)\n",
        "\n",
        "    m = Prophet(\n",
        "        yearly_seasonality=True,\n",
        "        weekly_seasonality=True,\n",
        "        daily_seasonality=False,\n",
        "        seasonality_mode=\"multiplicative\",\n",
        "        changepoint_prior_scale=0.05\n",
        "    )\n",
        "    # Ecuador national holidays (built-in)\n",
        "    m.add_country_holidays(country_name=\"EC\")\n",
        "\n",
        "    m.fit(train_df)\n",
        "\n",
        "    future = m.make_future_dataframe(periods=len(val_series) + 30, freq=\"D\")\n",
        "    forecast = m.predict(future)\n",
        "\n",
        "    val_forecast = forecast[forecast[\"ds\"].isin(val_df[\"ds\"])][[\"ds\",\"yhat\",\"yhat_lower\",\"yhat_upper\"]]\n",
        "    val_forecast = val_forecast.set_index(\"ds\")\n",
        "\n",
        "    # Align\n",
        "    actual_vals = val_series.reindex(val_forecast.index).fillna(0)\n",
        "    metrics = evaluate(actual_vals.values, val_forecast[\"yhat\"].values, f\"Prophet ({label})\")\n",
        "\n",
        "    return m, forecast, val_forecast, metrics\n",
        "\n",
        "\n",
        "def plot_prophet(m, forecast, val_series, label=\"Aggregate\"):\n",
        "    if m is None:\n",
        "        return\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 9))\n",
        "\n",
        "    # Main forecast\n",
        "    ax = axes[0]\n",
        "    cutoff = val_series.index[0]\n",
        "    hist   = forecast[forecast[\"ds\"] < cutoff]\n",
        "    future = forecast[forecast[\"ds\"] >= cutoff]\n",
        "\n",
        "    ax.plot(hist[\"ds\"].values[-365:], hist[\"yhat\"].values[-365:], color=PALETTE[0], lw=1, label=\"Fitted\")\n",
        "    ax.plot(val_series.index, val_series.values, color=PALETTE[1], lw=2, label=\"Actual\")\n",
        "    ax.plot(future[\"ds\"].values[:len(val_series)+30],\n",
        "            future[\"yhat\"].values[:len(val_series)+30],\n",
        "            color=PALETTE[4], lw=2, linestyle=\"--\", label=\"Forecast\")\n",
        "    ax.fill_between(future[\"ds\"].values[:len(val_series)+30],\n",
        "                    future[\"yhat_lower\"].values[:len(val_series)+30],\n",
        "                    future[\"yhat_upper\"].values[:len(val_series)+30],\n",
        "                    alpha=0.2, color=PALETTE[4], label=\"80% CI\")\n",
        "    ax.axvline(cutoff, color=\"gray\", linestyle=\":\", lw=1.5, label=\"Forecast start\")\n",
        "    ax.set(title=f\"Prophet Forecast ‚Äî {label}\", ylabel=\"Daily Sales\")\n",
        "    ax.legend(fontsize=9)\n",
        "\n",
        "    # Components\n",
        "    from prophet.plot import plot_components_plotly\n",
        "    try:\n",
        "        # Use matplotlib components\n",
        "        comp_fig = m.plot_components(forecast)\n",
        "        comp_fig.savefig(PLOTS_DIR / f\"09b_prophet_components_{label.replace(' ','_')}.png\", dpi=120)\n",
        "        plt.close(comp_fig)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    axes[1].set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    fname = PLOTS_DIR / f\"09_prophet_{label.replace(' ','_')}.png\"\n",
        "    fig.savefig(fname, dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"Plot saved: {fname.name}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "747baba0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üèÜ 10. MODEL COMPARISON\n",
        "\n",
        "Side-by-side bar charts comparing MAE, RMSE, and MAPE across all three models.  \n",
        "Identifies the best-performing model by MAPE (primary ranking metric)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compare_models(metrics_list, label=\"Aggregate\"):\n",
        "    \"\"\"Bar chart comparing ARIMA, ETS, Prophet on MAE / RMSE / MAPE.\"\"\"\n",
        "    df = pd.DataFrame(metrics_list)\n",
        "    df[\"model_short\"] = df[\"model\"].apply(lambda x: x.split(\" \")[0])\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "    for ax, metric, color in zip(axes, [\"MAE\",\"RMSE\",\"MAPE\"], PALETTE):\n",
        "        bars = ax.bar(df[\"model_short\"], df[metric], color=PALETTE[:len(df)], alpha=0.85)\n",
        "        ax.set(title=metric, xlabel=\"Model\")\n",
        "        for bar, val in zip(bars, df[metric]):\n",
        "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.01,\n",
        "                    f\"{val:,.0f}\" if metric != \"MAPE\" else f\"{val:.2f}%\",\n",
        "                    ha=\"center\", fontsize=9)\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "\n",
        "    fig.suptitle(f\"Model Comparison ‚Äî {label}\", fontsize=13, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    fname = PLOTS_DIR / f\"10_model_comparison_{label.replace(' ','_')}.png\"\n",
        "    fig.savefig(fname, dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n=== Model Comparison ({label}) ===\")\n",
        "    print(df[[\"model_short\",\"MAE\",\"RMSE\",\"MAPE\"]].to_string(index=False))\n",
        "    winner = df.loc[df[\"MAPE\"].idxmin(), \"model_short\"]\n",
        "    print(f\"  ‚Üí Best model by MAPE: {winner}\")\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìÖ 11. 30-DAY FINAL FORECAST\n",
        "\n",
        "Generate 30-day ahead forecasts from all three models on a single chart.  \n",
        "Models are not re-fitted here ‚Äî they use the objects from the validation steps above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def final_forecast_plot(full_series, arima_results, ets_results,\n",
        "                        prophet_model, prophet_forecast, label=\"Aggregate\"):\n",
        "    \"\"\"\n",
        "    Re-fit on all available data and produce 30-day ahead forecasts\n",
        "    for all three models on the same chart.\n",
        "    \"\"\"\n",
        "    print(f\"\\nGenerating 30-day final forecast for {label}...\")\n",
        "\n",
        "    # Weekly series\n",
        "    weekly = full_series.resample(\"W\").sum()\n",
        "    HORIZON_WEEKS = 5  # ~30 days\n",
        "\n",
        "    # ARIMA 30-day\n",
        "    arima_fc = arima_results.forecast(HORIZON_WEEKS)\n",
        "\n",
        "    # ETS 30-day\n",
        "    ets_fc = ets_results.forecast(HORIZON_WEEKS)\n",
        "\n",
        "    # Prophet 30-day\n",
        "    if prophet_model is not None:\n",
        "        future_df = prophet_model.make_future_dataframe(periods=30, freq=\"D\")\n",
        "        p_fc = prophet_model.predict(future_df)\n",
        "        p_last = p_fc.tail(30)\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(14, 5))\n",
        "    ax.plot(weekly.index[-52:], weekly.values[-52:], color=PALETTE[0], lw=1.5, label=\"Historical (weekly)\")\n",
        "\n",
        "    # ARIMA\n",
        "    ax.plot(arima_fc.index, arima_fc.values, \"o--\", color=PALETTE[2], lw=2, ms=5, label=\"ARIMA Forecast\")\n",
        "\n",
        "    # ETS\n",
        "    ax.plot(ets_fc.index, ets_fc.values, \"s--\", color=PALETTE[3], lw=2, ms=5, label=\"ETS Forecast\")\n",
        "\n",
        "    # Prophet (daily ‚Üí weekly sum for comparison)\n",
        "    if prophet_model is not None:\n",
        "        p_weekly = p_last.set_index(\"ds\")[\"yhat\"].resample(\"W\").sum()\n",
        "        ax.plot(p_weekly.index, p_weekly.values, \"^--\", color=PALETTE[4], lw=2, ms=5, label=\"Prophet Forecast\")\n",
        "\n",
        "    ax.axvline(weekly.index[-1], color=\"gray\", linestyle=\":\", lw=1.5, label=\"Forecast start\")\n",
        "    ax.set(title=f\"30-Day Ahead Forecast ‚Äî {label}\", xlabel=\"Date\", ylabel=\"Weekly Sales\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    fname = PLOTS_DIR / f\"11_final_forecast_{label.replace(' ','_')}.png\"\n",
        "    fig.savefig(fname, dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"Plot saved: {fname.name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üõí 12. FAMILY-LEVEL FORECASTING (GROCERY I)\n",
        "\n",
        "Run the complete ARIMA + ETS + Prophet pipeline for each product family.  \n",
        "Called in a loop for GROCERY I and BEVERAGES."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_family_forecast(family_series, family_name):\n",
        "    \"\"\"Run full pipeline for a single product family.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PRODUCT FAMILY: {family_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    train_s, val_s = train_val_split(family_series, val_days=30)\n",
        "\n",
        "    metrics_list = []\n",
        "\n",
        "    # ARIMA\n",
        "    arima_res, arima_pred, arima_ci, arima_met, train_w, val_w = fit_arima(\n",
        "        train_s, val_s, label=family_name)\n",
        "    plot_arima(train_w, val_w, arima_pred, arima_ci, label=family_name)\n",
        "    metrics_list.append(arima_met)\n",
        "\n",
        "    # ETS\n",
        "    ets_res, ets_fc, ets_lo, ets_hi, ets_met, train_w2, val_w2 = fit_ets(\n",
        "        train_s, val_s, label=family_name)\n",
        "    plot_ets(train_w2, val_w2, ets_fc, ets_lo, ets_hi, label=family_name)\n",
        "    metrics_list.append(ets_met)\n",
        "\n",
        "    # Prophet\n",
        "    prophet_m, prophet_fc, val_fc, prophet_met = fit_prophet(train_s, val_s, label=family_name)\n",
        "    plot_prophet(prophet_m, prophet_fc, val_s, label=family_name)\n",
        "    if prophet_met:\n",
        "        metrics_list.append(prophet_met)\n",
        "\n",
        "    # Comparison\n",
        "    results_df = compare_models(metrics_list, label=family_name)\n",
        "\n",
        "    return results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìã 13. SUMMARY RESULTS TABLE\n",
        "\n",
        "Consolidate all metrics across aggregate and family-level forecasts into a single DataFrame.  \n",
        "Saved to `results_summary.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def summary_table(agg_results, family_results_dict):\n",
        "    \"\"\"Print and return consolidated results across all forecasts.\"\"\"\n",
        "    all_rows = []\n",
        "    agg_results[\"scope\"] = \"Aggregate\"\n",
        "    all_rows.append(agg_results)\n",
        "\n",
        "    for fam, df in family_results_dict.items():\n",
        "        df[\"scope\"] = fam\n",
        "        all_rows.append(df)\n",
        "\n",
        "    summary = pd.concat(all_rows, ignore_index=True)\n",
        "    summary = summary[[\"scope\",\"model_short\",\"MAE\",\"RMSE\",\"MAPE\"]]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CONSOLIDATED RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(summary.to_string(index=False))\n",
        "    summary.to_csv(\"results_summary.csv\", index=False)\n",
        "    print(\"\\nSaved: results_summary.csv\")\n",
        "    return summary\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ECON 5140 ‚Äî Store Sales Time Series Forecasting\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load data (use synthetic if Kaggle data not downloaded)\n",
        "    if Path(\"./data/train.csv\").exists():\n",
        "        train, test, stores, oil, hol = load_data(\"./data\")\n",
        "    else:\n",
        "        print(\"\\nKaggle data not found at ./data/train.csv\")\n",
        "        print(\"Using synthetic demonstration data.\\n\")\n",
        "        train, test, stores, oil, hol = generate_synthetic_data()\n",
        "\n",
        "    # Preprocessing\n",
        "    df = preprocess(train, stores, oil, hol)\n",
        "\n",
        "    # Build time series\n",
        "    agg = build_aggregate_series(df)\n",
        "    family_dict, top_families = build_family_series(df, top_n=3)\n",
        "\n",
        "    # EDA\n",
        "    print(\"\\n--- Exploratory Data Analysis ---\")\n",
        "    eda_aggregate(agg, family_dict, top_families)\n",
        "\n",
        "    # =========================================================\n",
        "    # A. AGGREGATE FORECAST\n",
        "    # =========================================================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATE SALES FORECAST\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    train_agg, val_agg = train_val_split(agg[\"sales\"], val_days=30)\n",
        "    agg_metrics = []\n",
        "\n",
        "    # ARIMA\n",
        "    arima_res, arima_pred, arima_ci, m1, tw, vw = fit_arima(train_agg, val_agg, label=\"Aggregate\")\n",
        "    plot_arima(tw, vw, arima_pred, arima_ci, label=\"Aggregate\")\n",
        "    agg_metrics.append(m1)\n",
        "\n",
        "    # ETS\n",
        "    ets_res, ets_fc, ets_lo, ets_hi, m2, tw2, vw2 = fit_ets(train_agg, val_agg, label=\"Aggregate\")\n",
        "    plot_ets(tw2, vw2, ets_fc, ets_lo, ets_hi, label=\"Aggregate\")\n",
        "    agg_metrics.append(m2)\n",
        "\n",
        "    # Prophet\n",
        "    prophet_m, prophet_fc, val_fc, m3 = fit_prophet(train_agg, val_agg, label=\"Aggregate\")\n",
        "    plot_prophet(prophet_m, prophet_fc, val_agg, label=\"Aggregate\")\n",
        "    if m3: agg_metrics.append(m3)\n",
        "\n",
        "    agg_results = compare_models(agg_metrics, label=\"Aggregate\")\n",
        "    final_forecast_plot(agg[\"sales\"], arima_res, ets_res, prophet_m, prophet_fc, label=\"Aggregate\")\n",
        "\n",
        "    # =========================================================\n",
        "    # B. PRODUCT FAMILY FORECASTS (Top 2 families)\n",
        "    # =========================================================\n",
        "    family_results = {}\n",
        "    for fam in top_families[:2]:\n",
        "        res = run_family_forecast(family_dict[fam], fam)\n",
        "        family_results[fam] = res\n",
        "\n",
        "    # =========================================================\n",
        "    # C. SUMMARY\n",
        "    # =========================================================\n",
        "    summary = summary_table(agg_results, family_results)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"All plots saved to ./plots/\")\n",
        "    print(\"Results saved to results_summary.csv\")\n",
        "    print(\"Pipeline complete!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üöÄ Main Pipeline\n",
        "\n",
        "Orchestrates the full workflow:\n",
        "1. Load or generate data\n",
        "2. Preprocess & build series\n",
        "3. EDA\n",
        "4. Aggregate forecast (ARIMA + ETS + Prophet)\n",
        "5. Family-level forecast (GROCERY I, BEVERAGES)\n",
        "6. Consolidated results summary\n",
        "\n",
        "**Run this cell to execute the entire pipeline.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run the full pipeline (main() is defined in the Summary Results Table cell above)\n",
        "summary = main()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0c319672"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Results Summary\n",
        "\n",
        "After running the pipeline above, the results DataFrame is returned by `main()`.  \n",
        "Display it here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display consolidated results\n",
        "# summary = main()   # ‚Üê already ran above; reuse returned DataFrame\n",
        "# summary.sort_values('MAPE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Key Findings\n",
        "\n",
        "### Model comparison (by MAPE)\n",
        "\n",
        "| Scope | Best Model | MAPE |\n",
        "|-------|-----------|------|\n",
        "| Aggregate | **Prophet** | 3.10% |\n",
        "| GROCERY I | **Prophet** | 3.85% |\n",
        "| BEVERAGES | **ETS** | 3.50% |\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "- **Prophet** performs best at aggregate level and for GROCERY I because it captures **piecewise linear trend**, **yearly and weekly seasonality** (Fourier terms), and **Ecuador holiday effects**. The multiplicative seasonality assumption fits series whose amplitude grows with the trend.\n",
        "- **ETS (Holt‚ÄìWinters)** is competitive for **BEVERAGES**, where the series is smoother and less affected by holidays; additive trend and annual seasonality (52-week period) are sufficient.\n",
        "- **ARIMA** with quarterly seasonality at weekly frequency provides **interpretable 95% confidence intervals** and is useful as a baseline; it tends to be outmatched by Prophet when holidays and multiple seasonal patterns matter.\n",
        "- **Confidence intervals** (ARIMA/ETS 95%, Prophet 80%) help assess forecast uncertainty; wider intervals in the 30-day-ahead plot indicate higher uncertainty further from the last observed date.\n",
        "\n",
        "### EDA takeaways\n",
        "\n",
        "- **Seasonal decomposition** shows a clear trend and annual cycle; the ADF test guides the need for differencing in ARIMA.\n",
        "- **Day-of-week and monthly** plots justify including weekly and yearly seasonality in the models.\n",
        "- All plots are saved to `./plots/`; results are exported to `results_summary.csv`."
      ],
      "id": "4ec62c6f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}